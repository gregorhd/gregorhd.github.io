{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2079bb1",
   "metadata": {},
   "source": [
    "## Remote sensing urban growth in Nakuru, Kenya - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e3c9e",
   "metadata": {},
   "source": [
    "If this is your first time working with _geemap_, or virtual conda environments, geemap's [tutorials](https://geemap.org/tutorials/#3-introducing-the-inspector-tool-for-earth-engine-python-api) will guide you through installing the package and making your first steps. The workflow below partly follows _geemap_ tutorial [no. 32](https://youtu.be/qWaEfgWi21o).\n",
    "\n",
    "### Getting started\n",
    "\n",
    "We first import `geemap` and the GEE Python API, defining the region of interest we already used in [Part 1](https://gregorhd.github.io/nakuru-pt1/). We then instantiate a *geemap* `Map` object and center the resulting *leaflet* map on our region of interest to get our bearings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae33b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33eb228",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roi = ee.Geometry.Polygon(\n",
    "        [[[35.750324, -0.480940], \n",
    "          [35.750324, -0.108933], \n",
    "          [36.261697, -0.108933], \n",
    "          [36.261697, -0.480940], \n",
    "          [35.750324, -0.480940]]], None, False)\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(roi, zoom=11)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b2676",
   "metadata": {},
   "source": [
    "Next we add a Landsat 8 scene from around the time (2018-19) of the latest issue of the 100m resolution [Copernicus CGLS-LC100 Collection 3](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_Landcover_100m_Proba-V-C3_Global) land cover dataset which we will use to train a classifier. While not a perfect match, this should be a sufficient approximation. We sort the `ImageCollection` by cloud cover, select the first of these and clip the scene to our region of interest.\n",
    "\n",
    "Let's also verify the scene's percentage of cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L8_2018 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1\") \\\n",
    "    .filterBounds(roi) \\\n",
    "    .filterDate('2018-10-01', '2018-10-31') \\\n",
    "    .sort('CLOUD_COVER') \\\n",
    "    .first() \\\n",
    "    .clip(roi)\n",
    "\n",
    "L8_2018.get('CLOUD_COVER').getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957cc15",
   "metadata": {},
   "source": [
    "Let's add this to our map as a true color composite, though we could just as well skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_params = {'min': 0,\n",
    "    'max': 25000,'bands': ['B4','B3', 'B2']}\n",
    "\n",
    "Map.addLayer(L8_2018, vis_params, \"Landsat 8, raw (2018)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5194fd0",
   "metadata": {},
   "source": [
    "### Adding a reference layer and generating sample points\n",
    "\n",
    "Next, we add the latest Copernicus land cover dataset, again clipping it to our ROI.\n",
    "\n",
    "We should also compare the dates of acquisition for the training and input dataset to make sure they're roughly in the same ballpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc47be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reference landcover data\n",
    "\n",
    "copernicus_lc = ee.ImageCollection(\"COPERNICUS/Landcover/100m/Proba-V-C3/Global\") \\\n",
    "    .select(\"discrete_classification\") \\\n",
    "    .sort('system:time_start', False) \\\n",
    "    .first() \\\n",
    "    .clip(roi)\n",
    "\n",
    "print(\"Landsat 8 date of acquisition: \", ee.Date(L8_2018.get('system:time_start')).format('YYYY-MM-dd').getInfo())\n",
    "print(\"Copernicus issue date: \", ee.Date(copernicus_lc.get('system:time_start')).format('YYYY-MM-dd').getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a222b89",
   "metadata": {},
   "source": [
    "Next, we'll generate a `FeatureCollection` of 10,000 random points across our ROI and have each point sample the land cover classification data from Copernicus (as can be seen by examining the first point in the `FeatureCollection` below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cbfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 5,000 random points\n",
    "points = copernicus_lc.sample(**{\n",
    "    'region': roi,\n",
    "    'scale': 30,\n",
    "    'numPixels': 10000,\n",
    "    'seed': 0,\n",
    "    'geometries': True  # Set this to False to ignore geometries\n",
    "})\n",
    "\n",
    "print(points.first().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sample points to the Map, if you wish, by uncommenting this line\n",
    "# Map.addLayer(points, {}, 'Random points', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81571c3c",
   "metadata": {},
   "source": [
    "### Training the classifier\n",
    "\n",
    "In this step, each band's pixel values from Landsat 8 will be added to the attributes of the *points* `FeatureCollection` which we'll then use to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these bands of the Landsat 8 scene for predicting the likely land cover class\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "\n",
    "\n",
    "# This band in the Copernicus ImageCollection stores the actual numeric land cover information\n",
    "# which we will use for training the classifier\n",
    "# see: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_Landcover_100m_Proba-V-C3_Global#bands\n",
    "label = 'discrete_classification'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "# see: https://developers.google.com/earth-engine/apidocs/ee-image-sampleregions\n",
    "training = L8_2018.select(bands).sampleRegions(**{\n",
    "  'collection': points,\n",
    "  'properties': [label],\n",
    "  'scale': 30\n",
    "})\n",
    "\n",
    "# Here we choose the Random Forest algorithm with 15 decision trees.\n",
    "# Feel free to experiment with either this number or any of the other algorithms available.\n",
    "# Some, like Support Vector Machines, will take significantly longer to complete.\n",
    "# see here and following: https://developers.google.com/earth-engine/apidocs/ee-classifier-amnhmaxent\n",
    "classifier = ee.Classifier.smileRandomForest(15).train(training, label, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3192bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efb5dc",
   "metadata": {},
   "source": [
    "### Classifying a Landsat 8 scene from 2020\n",
    "\n",
    "This is where the rubber hits the road and we actually classify a Landsat 8 scene based on the Copernicus training data we just collected. The scene we're going to classify, however, will not be the one we used for training but instead the  same scene we manually classified in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834db20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L8_2020 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1\") \\\n",
    "    .filterBounds(roi) \\\n",
    "    .filterDate('2020-10-08', '2020-10-09') \\\n",
    "    .sort('system:time_start') \\\n",
    "    .first() \\\n",
    "    .clip(roi)\n",
    "\n",
    "# Classify the image using the same bands used for training.\n",
    "result_2020 = L8_2020.select(bands).classify(classifier)\n",
    "\n",
    "# Display the classified image with random colors.\n",
    "Map.addLayer(result_2020.randomVisualizer(), {}, 'Landcover (random colors)')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66343b88",
   "metadata": {},
   "source": [
    "### Simplifying land cover classes\n",
    "\n",
    "Our brains have difficulty differentiating more than 10 or 12 colors at a time, let alone 23 as in this case. That's why it will make sense to merge many of the classes into one. In our case, four main classes may be enough to tell a compelling story.\n",
    "\n",
    "But first, we need to understand which of the numeric values correspond to which real-world land cover classes. For this we, we could either simply check the discrete_classification Class Table on [this](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_Landcover_100m_Proba-V-C3_Global#bands) page, or extract the class names and values form the dataset itself, and 'zip' these two lists into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e58fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = copernicus_lc.get('discrete_classification_class_values').getInfo()\n",
    "class_names = copernicus_lc.get('discrete_classification_class_names').getInfo()\n",
    "\n",
    "zipped = list(zip(class_values, class_names))\n",
    "zipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832353a9",
   "metadata": {},
   "source": [
    "Next, we create lists of equal length with the old and new values for each of the four landcover classes we envision, finally combining them into two ordered composite lists. These then go into the `.remap()` method for our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_orig = [50]\n",
    "urban_new = [1]\n",
    "\n",
    "natveg_orig = [20, 30, 90, 100, 111, 112, 113, 114, 115, 116, 121, 122, 123, 124, 125, 126]\n",
    "natveg_new = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "nonurb_orig = [0, 40, 60, 70, 200]\n",
    "nonurb_new = [3, 3, 3, 3, 3]\n",
    "\n",
    "water_orig = [80]\n",
    "water_new = [4]\n",
    "\n",
    "orig = urban_orig + natveg_orig + nonurb_orig + water_orig\n",
    "new = urban_new + natveg_new + nonurb_new + water_new\n",
    "\n",
    "# Remap the new consecutive integer values to the new ones\n",
    "final_2020 = result_2020.remap(orig, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce022273",
   "metadata": {},
   "source": [
    "Lastly, we define legend keys and an ordered color palette which will inform both our `vis_params` in the `addLayer` method as well as the symbology for our legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702e59f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "legend_keys = ['Urban', 'Natural vegetation', 'Cropland or barren soil', 'Water bodies']\n",
    "\n",
    "class_palette = ['000000', '00CC00', 'FFFF00', '009EE0']\n",
    "\n",
    "Map.add_legend(legend_keys=legend_keys, legend_colors=class_palette, position='bottomright')\n",
    "\n",
    "Map.addLayer(final_2020, {'palette': class_palette}, 'Landcover (2020)')\n",
    "\n",
    "# remove the layers we don't need\n",
    "Map.remove_layer(Map.find_layer('Landsat 8, raw (2018)'))\n",
    "Map.remove_layer(Map.find_layer('Landcover (random colors)'))\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d9b39",
   "metadata": {},
   "source": [
    "### Classifying a Landsat 8 scene from 2013\n",
    "\n",
    "Let's now also classify a Landsat 8 scene from right after the satellite's launch in 2013 but still in the month of October, just like the 2020 scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us a scene from 5 October, 2013\n",
    "L8_2013 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1\") \\\n",
    "    .filterBounds(roi) \\\n",
    "    .filterDate('2013-10-01', '2013-10-31') \\\n",
    "    .sort('CLOUD_COVER') \\\n",
    "    .first() \\\n",
    "    .clip(roi)\n",
    "\n",
    "# Classify the image using the same bands used for training.\n",
    "result_2013 = L8_2013.select(bands).classify(classifier)\n",
    "\n",
    "final_2013 = result_2013.remap(orig, new)\n",
    "\n",
    "Map.addLayer(final_2013, {'palette': class_palette}, 'Landcover (2013)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca8f1d",
   "metadata": {},
   "source": [
    "### Classifying a Landsat 7 scene from 2002\n",
    "\n",
    "As our analysis in Part 1 began in 2002, let's also classify the same scene here using Google Earth Engine. This time, though, we'll use the [MCD12Q1.006 MODIS Land Cover Type Yearly Global 500m](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MCD12Q1#description) as our training dataset since this started providing data in 2001. Specifically, we'll use the University of Maryland classification (band name '[LC_Type2](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MCD12Q1#bands)').\n",
    "\n",
    "With a 500m ground resolution, this dataset is a lot coarser, so the results will not be as accurate as with the 100m Copernicus dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L7_2002 = ee.ImageCollection('LANDSAT/LE07/C01/T1') \\\n",
    "    .filterBounds(roi) \\\n",
    "    .filterDate('2002-09-13', '2002-09-14') \\\n",
    "    .sort('system:time_start') \\\n",
    "    .first() \\\n",
    "    .clip(roi)\n",
    "\n",
    "MCD_500 = ee.ImageCollection(\"MODIS/006/MCD12Q1\") \\\n",
    "    .select(\"LC_Type2\") \\\n",
    "    .filterDate('2003-01-01') \\\n",
    "    .first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 5,000 random points\n",
    "points2 = MCD_500.sample(**{\n",
    "    'region': roi,\n",
    "    'scale': 30,\n",
    "    'numPixels': 10000,\n",
    "    'seed': 0,\n",
    "    'geometries': True  # Set this to False to ignore geometries\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4acfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slight adjustments to the bands since L7's are different to L8's\n",
    "bands2 = ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']\n",
    "\n",
    "# Adjust label name\n",
    "label2 = 'LC_Type2'\n",
    "\n",
    "training2 = L7_2002.select(bands2).sampleRegions(**{\n",
    "  'collection': points2,\n",
    "  'properties': [label2],\n",
    "  'scale': 30\n",
    "})\n",
    "\n",
    "classifier2 = ee.Classifier.smileRandomForest(15).train(training2, label2, bands2)\n",
    "\n",
    "result_2002 = L7_2002.select(bands2).classify(classifier2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0eb4b",
   "metadata": {},
   "source": [
    "As before, we'll recode the landcover types into four very broad categories. Feel free to follow a more finegrained approach here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_orig = [13]\n",
    "urban_new = [1]\n",
    "\n",
    "natveg_orig = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "natveg_new = [2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "nonurb_orig = [10, 12, 14, 15]\n",
    "nonurb_new = [3, 3, 3, 3]\n",
    "\n",
    "water_orig = [0, 11]\n",
    "water_new = [4, 4]\n",
    "\n",
    "orig = urban_orig + natveg_orig + nonurb_orig + water_orig\n",
    "new = urban_new + natveg_new + nonurb_new + water_new\n",
    "\n",
    "# Remap the new consecutive integer values to the new ones and add the new layer\n",
    "final_2002 = result_2002.remap(orig, new).clip(roi)\n",
    "\n",
    "Map.addLayer(final_2002, {'palette': class_palette}, 'Landcover (2002)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b341f",
   "metadata": {},
   "source": [
    "### Final output\n",
    "\n",
    "And this is the final result. You can tick and untick the three layers to compare. The bottom-most ticked layer in the layer manager is always the 'top' layer visible. Due to the two satellites and training datasets involved, the results are not 100% comparable, but close enough. You will also see significant differences in classification between the results here and those in Part 1. There are plenty of moving parts and, if your are so inclined, you are free to experiment both with other training datasets and classifiers at your disposal, each with their own set of parameters. In any case, the main purpose here was to introduce the significant capabilities of both _geemap_, Google Earth Engine and the Python environment for scalable remote sensing applications.\n",
    "\n",
    "As always, critique and comments are more than welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbdaeac",
   "metadata": {},
   "source": [
    "### Saving to HTML\n",
    "\n",
    "At the time of writing I had to also install the _leafmap_ package for the exported HTML to properly open in the browser, possibly due to some recent _ipyleaflet_ updates. If this is the case for you too, simply run\n",
    "\n",
    "`conda install -c conda-forge leafmap`\n",
    "\n",
    "before proceeding. Occasionally, `leafmap.update_package()`, followed by a kernel restart may also be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd008e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the map to your Downloads folder\n",
    "import os\n",
    "\n",
    "download_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "html_file = os.path.join(download_dir, 'Nakuru_pt2.html')\n",
    "\n",
    "Map.to_html(outfile=html_file, title='Remote sensing urban growth in Nakuru, Kenya - Part 2', width='100%', height='880px')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a43dc9",
   "metadata": {},
   "source": [
    "## Annex\n",
    "\n",
    "### Manual sample collection\n",
    "\n",
    "But what do you do if you don't have a very good (or any) training dataset or simply want to collect samples yourself based on your own experience? The workflow below is an attempt at doing just that, though the low number of classes used will give your very mixed results. If you have the time, I recommend first sampling at least 6-8 classes and merging those after.\n",
    "\n",
    "We will have to collect at least 20 sample points for each information class we plan to classify. Every time we're done sampling, we need to assign the drawn features to a `FeatureCollection` and define a property for each feature. This then tells the classifier which landcover class we think this pixel represents. It helps to inspect the spectral profile of each area or pixel via the \"Plotting\" tool in the control panel prior to placing a marker, to confirm that the spectral profile matches with the type of landcover we're currently collecting samples for. Adjusting the `vis_params` to other band combinations (e.g. 4-3-2 for vegetation or 4-5-3 for urban) may also help to visually hone in on certain areas.\n",
    "\n",
    "So let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e76f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First, place at least 20 markers onto urban areas using any map instance created.\n",
    "\n",
    "# Once you're done collecting, assign those markers to a FeatureCollection\n",
    "\n",
    "urban = ee.FeatureCollection(Map.draw_features)\n",
    "\n",
    "# then, define a function which will set a 'class' property to the value of a global scope variable\n",
    "# we set prior to calling the map function\n",
    "\n",
    "def set_class(feature):\n",
    "    return feature.set({'class': class_val})\n",
    "\n",
    "class_val = 1\n",
    "\n",
    "urban = urban.map(set_class)\n",
    "\n",
    "# Let's verify that this worked\n",
    "print(urban.first().getInfo())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bf1265",
   "metadata": {},
   "source": [
    "Now clear the drawn features via the respective button in the control panel in the top right of the map.\n",
    "\n",
    "We'll now collect samples for natural vegetation. Set the vis_params to a NIR false color composite (4-3-2) and pick out pixels in deep red. When you're done collecting, again assign the drawn features to a FeatureCollection and set their 'class' property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "natveg = ee.FeatureCollection(Map.draw_features)\n",
    "\n",
    "class_val = 2\n",
    "\n",
    "natveg = natveg.map(set_class)\n",
    "\n",
    "print(natveg.first().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By now, you know the drill: clear, collect, assign and set_class\n",
    "\n",
    "nonurb = ee.FeatureCollection(Map.draw_features)\n",
    "\n",
    "class_val = 3\n",
    "\n",
    "nonurb = nonurb.map(set_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, our last information class: water.\n",
    "\n",
    "water = ee.FeatureCollection(Map.draw_features)\n",
    "\n",
    "class_val = 4\n",
    "\n",
    "water = water.map(set_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e13a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll merge all four FeatureCollections into one\n",
    "\n",
    "points2 = urban.merge(natveg).merge(nonurb).merge(water)\n",
    "\n",
    "# Let's see how many samples we have in total - clearly less than then 10,000 above, so the results are likely not going to be on par\n",
    "points2.size().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a37f",
   "metadata": {},
   "source": [
    "Everything from here on out is replicating what we did above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96049960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slight adjustments to the bands since L7's are different to L8's, as well as the label we chose above\n",
    "bands2 = ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']\n",
    "\n",
    "label2 = 'class'\n",
    "\n",
    "training2 = L7_2002.select(bands2).sampleRegions(**{\n",
    "  'collection': points2,\n",
    "  'properties': [label2],\n",
    "  'scale': 30\n",
    "})\n",
    "\n",
    "classifier2 = ee.Classifier.smileRandomForest(15).train(training2, label2, bands2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2002 = L7_2002.select(bands2).classify(classifier2)\n",
    "\n",
    "# final_2002 = result_2002.remap(orig, new)\n",
    "\n",
    "Map.addLayer(final_2002, {'min': 1, 'max': 4, 'palette': class_palette}, 'Landcover (2002)')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ea6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
